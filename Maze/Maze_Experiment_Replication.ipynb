{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maze Experiment Replication"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is an extension of the previous `Maze Experience` Notebook. Here, we will be running the full experiment on larger datasets, and evaluating the algorithm's performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, make sure the path inside the parenthesis is the path that contains the algorithm code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/janiceyang/Dropbox (MIT)/ORC UROP/Opioids/Algorithm/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pandas as pd\n",
    "import gym\n",
    "import gym_maze\n",
    "import pickle\n",
    "import plotly.express as px\n",
    "\n",
    "from model import MDP_model\n",
    "from maze_functions import createSamples, opt_maze_trajectory, opt_model_trajectory, policy_accuracy, \\\n",
    "    get_maze_transition_reward, plot_paths, value_diff, get_maze_MDP, value_est, opt_path_value_diff\n",
    "from MDPtools import SolveMDP\n",
    "from testing import cluster_size, next_clusters, training_value_error, purity, plot_features, testing_value_error, \\\n",
    "    generalization_accuracy\n",
    "\n",
    "mazes = {1: 'maze-v0',\n",
    "         2: 'maze-sample-3x3-v0',\n",
    "         3: 'maze-random-3x3-v0',\n",
    "         4: 'maze-sample-5x5-v0',\n",
    "         5: 'maze-random-5x5-v0',\n",
    "         6: 'maze-sample-10x10-v0',\n",
    "         7: 'maze-random-10x10-v0',\n",
    "         8: 'maze-sample-100x100-v0',\n",
    "         9: 'maze-random-100x100-v0',\n",
    "         10: 'maze-random-10x10-plus-v0', # has portals \n",
    "         11: 'maze-random-20x20-plus-v0', # has portals \n",
    "         12: 'maze-random-30x30-plus-v0'} # has portals "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset parameters\n",
    "N = 200\n",
    "T_max = 25\n",
    "r = 0.4\n",
    "maze = mazes[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Fitting Parameters\n",
    "max_k = 25\n",
    "classification = 'DecisionTreeClassifier'\n",
    "split_classifier_params = {'random_state':0, 'max_depth':2}\n",
    "clustering = 'Agglomerative'\n",
    "n_clusters = None\n",
    "distance_threshold = 0.5\n",
    "precision_thresh = 1e-14\n",
    "random_state = 0\n",
    "pfeatures = 2\n",
    "gamma = 1\n",
    "actions = [0, 1, 2, 3]\n",
    "h = -1\n",
    "cv = 5\n",
    "th = 0\n",
    "eta = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating optimal/true values for the maze\n",
    "P, R = get_maze_MDP(maze)\n",
    "f, rw = get_maze_transition_reward(maze)\n",
    "true_v, true_pi = SolveMDP(P, R, prob='max', gamma=1, epsilon=1e-8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we must decide how to split the paths in each dataset, to evaluate the algorithm's performance as we feed it incrementally more data. Make a list of Ns (number of paths) we want to plot, and be sure the last maximum value is equal to the parameter N (total paths) above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ns = [10, 20, 30, 40, 50, 70, 90, 110, 130, 150, 170, 200]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) Creating New Datasets:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can choose to create and save new datasets to be trained here: simply link the folder you save the data in to the `path` section of the Training. Otherwise, you can also train the model using pre-made datasets provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose number of sets to create\n",
    "sets = 10\n",
    "\n",
    "for n in range(sets):\n",
    "    df = createSamples(N, T_max, maze, r, reseed=True)\n",
    "    df.to_csv(f'set_{n}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will fit models to the datasets! Be sure the datasets used are named as 'set_#.csv', starting with 'set_0.csv' onwards, and that they follow the same column format as the samples provided. Input the total number of sets you would like to train below, and whether you would like to save the trained models below. \n",
    "\n",
    "If you already have trained models, skip this step and simply load the models into the notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_sets = 10\n",
    "save_model = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = '/Users/janiceyang/Dropbox (MIT)/ORC UROP/Opioids_Dropbox/Maze/Model Data/Datasets/Set 1 (N=200, T_max = 25, randomness=0.4)'\n",
    "path = '/Users/janiceyang/Dropbox (MIT)/ORC UROP/Opioids_Dropbox/Maze/Model Data/Datasets/Set 2 (risk = -0.04)'\n",
    "sys.path.append(path)\n",
    "\n",
    "all_models = []\n",
    "for set_num in range(total_sets):\n",
    "    filename = f'set_{set_num}.csv'\n",
    "    df = pd.read_csv(path+'/'+filename)\n",
    "\n",
    "    # taking out extra ID col and changing actions back to integers\n",
    "    df = df.iloc[:, 1:]\n",
    "    df.loc[df['ACTION']=='None', 'ACTION'] = 4\n",
    "    df['ACTION'] = pd.to_numeric(df['ACTION'], downcast='integer')\n",
    "    df.loc[df['ACTION']==4, 'ACTION'] = 'None'\n",
    "    \n",
    "    df_full = df.copy()\n",
    "    \n",
    "    models=[]\n",
    "    for n in Ns:\n",
    "        df_small = df_full.loc[df_full['ID']<n]\n",
    "\n",
    "        m = MDP_model()\n",
    "        m.fit(df_small, # df: dataframe in the format ['ID', 'TIME', ...features..., 'RISK', 'ACTION']\n",
    "            pfeatures, # int: number of features\n",
    "            h, # int: time horizon (# of actions we want to optimize)\n",
    "            gamma, # discount factor\n",
    "            max_k, # int: number of iterations\n",
    "            distance_threshold, # clustering diameter for Agglomerative clustering\n",
    "            cv, # number for cross validation\n",
    "            th, # splitting threshold\n",
    "            eta, # incoherence threshold\n",
    "            precision_thresh, # precision threshold\n",
    "            classification, # classification method\n",
    "            split_classifier_params, # classification params\n",
    "            clustering,# clustering method from Agglomerative, KMeans, and Birch\n",
    "            n_clusters, # number of clusters for KMeans\n",
    "            random_state, # random seed\n",
    "            plot=False,\n",
    "            optimize=True,\n",
    "            verbose=False)\n",
    "        print('N=', n, ' completed')\n",
    "        models.append(m)\n",
    "        \n",
    "        if save_model:\n",
    "            pickle.dump(m, open(f'round_{set_num}_model_N={n}.sav', 'wb'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Models (Optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load your saved models into a list of lists, where `all_models` includes lists of models sorted by dataset and in ascending order of datasize `Ns` used. Sample code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models = []\n",
    "\n",
    "for i in range(total_sets): \n",
    "    models = []\n",
    "    for n in Ns: \n",
    "        m = pickle.load(open(f'round_{i}_model_N={n}.sav', 'rb'))\n",
    "        models.append(m)\n",
    "    all_models.append(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimality Gap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Optimality Gap represents the difference between the value, `v_alg`, found by simulating a player starting from the starting cell and taking `t_max` number of actions as prescribed by the trained model, compared with the true value `v_opt` of the maze, by taking `t_max` number of optimal actions. `v_alg` is calculated by randomly generating `K` points in the starting cell, simulating these `t_max` steps in the maze (summing the value of each step). The average of `|v_alg-v_opt*|` across `K` trials is returned. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 100\n",
    "save_opt_gap = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gap = np.zeros(len(Ns))\n",
    "\n",
    "for i, model_set in enumerate(all_models):\n",
    "    opt_gap = value_diff(model_set, Ns, K, T_max, P, R, f, rw, true_v, true_pi)\n",
    "    gap += opt_gap\n",
    "    \n",
    "    if save_opt_gap: \n",
    "        pickle.dump(opt_gap, open(f'round_{i}_opt_gap.sav', 'wb'))\n",
    "        \n",
    "avg_opt_gap = gap/len(all_models)\n",
    "opt_gap_norm = avg_opt_gap/0.44 #0.44 is v_opt\n",
    "\n",
    "# plot\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.plot(Ns, opt_gap_norm, 'bo-')\n",
    "ax1.set_title('Optimality Gap')\n",
    "ax1.set_xlabel('Number of trajectories N')\n",
    "ax1.set_ylabel('MAPE')\n",
    "ax1.set_ylim(0, 3.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Value Estimate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Value Estimate represents the difference between the value of a random starting point (in the first cell) according to the optimal MDP clustering, compared to the value of the point clustered into the model's MDP. This difference is truncated at a maximum of 1 -- `min(1, difference)` is taken -- and `K` trials are run and averaged per model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 100\n",
    "save_val_est = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gap = np.zeros(len(Ns))\n",
    "\n",
    "for i, model_set in enumerate(all_models):\n",
    "    val_est = value_est(model_set, Ns, K, P, R, f, rw, true_v, true_pi)\n",
    "    gap += val_est\n",
    "    \n",
    "    if save_val_est: \n",
    "        pickle.dump(val_est, open(f'round_{i}_val_est.sav', 'wb'))\n",
    "        \n",
    "avg_est = gap/len(all_models)\n",
    "avg_est_norm = avg_est/0.44 #0.44 is v_opt\n",
    "    \n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.plot(Ns, avg_est_norm, 'bo-')\n",
    "ax1.set_title('Value Estimation')\n",
    "ax1.set_xlabel('Number of trajectories N')\n",
    "ax1.set_ylabel('MAPE')\n",
    "ax1.set_ylim(0, 3.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimal Action Value Difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Optimal Action Value Difference calculates difference in cumulative value between a point randomly generated in the starting cell and taking the true optimal set of actions for `T_max` steps through the real environment, compared to the same point taking the same sequence of actions within the trained model's MDP environment. `K` randomly generated points are used, with the average of the difference (truncated at maximum 1) returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 100\n",
    "save_opt_act_gap = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gap = np.zeros(len(Ns))\n",
    "\n",
    "for i, model_set in enumerate(all_models):\n",
    "    opt_act_gap = opt_path_value_diff(model_set, Ns, K, T_max, P, R, f, rw, true_v, true_pi)\n",
    "    gap += opt_act_gap\n",
    "    \n",
    "    if save_opt_act_gap: \n",
    "        pickle.dump(opt_act_gap, open(f'round_{i}_opt_acdt_gap.sav', 'wb'))\n",
    "    \n",
    "opt_gap = gap/len(all_models)\n",
    "opt_gap_norm = opt_gap/0.44\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.plot(Ns, opt_gap_norm, 'bo-')\n",
    "ax1.set_title('Value Estimation')\n",
    "ax1.set_xlabel('Number of trajectories N')\n",
    "ax1.set_ylabel('MAPE')\n",
    "ax1.set_ylim(0, 3.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Averages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can calculate the classification accuracies of the model when measured on the seen training data, as well as a randomly generated testing dataset. The classification accuracy is defined as the percentage of points that the model correctly clusters, based on known original grids of the maze. The classification error, in turn, is defined as the percentage of points that are incorrectly clustered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_averages = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_acc = np.zeros(len(Ns))\n",
    "test_acc = np.zeros(len(Ns))\n",
    "\n",
    "for i, model_set in enumerate(all_models):\n",
    "    df_test = createSamples(N, T_max, maze, r, reseed=True)\n",
    "    training_acc, testing_acc = generalization_accuracy(model_set, df_test, Ns)\n",
    "    \n",
    "    tr_acc += training_acc\n",
    "    test_acc += testing_acc\n",
    "    \n",
    "    if save_averages:\n",
    "        pickle.dump(training_acc, open(f'round_{i}_training_acc.sav', 'wb'))\n",
    "        pickle.dump(testing_acc, open(f'round_{i}_testing_acc.sav', 'wb'))\n",
    "\n",
    "train_acc = tr_acc/len(all_models)\n",
    "testing_acc = test_acc/len(all_models)\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.plot(Ns, 1-np.array(testing_acc), 'bo--', label='Out-of-Sample')\n",
    "ax1.set_title('Classification Error')\n",
    "ax1.set_xlabel('Number of trajectories N')\n",
    "ax1.set_ylabel('% Error')\n",
    "ax1.legend()\n",
    "ax1.set_ylim(0, 1)\n",
    "\n",
    "fig4, ax4 = plt.subplots()\n",
    "ax4.plot(Ns, 1-np.array(testing_acc), 'bo-', label='Out-of-Sample')\n",
    "ax4.plot(Ns, 1-np.array(train_acc), 'mo--', label='In-Sample')\n",
    "ax4.set_title('Classification Error')\n",
    "ax4.set_xlabel('Number of trajectories N')\n",
    "ax4.set_ylabel('% Error')\n",
    "ax4.legend()\n",
    "ax4.set_ylim(0, 1)\n",
    "\n",
    "fig2, ax2 = plt.subplots()\n",
    "ax2.plot(Ns, train_acc, 'mo-', label='Training Accuracy')\n",
    "ax2.plot(Ns, np.array(testing_acc), 'bo--', label='Testing Accuracy')\n",
    "ax2.set_title('Classification Accuracy')\n",
    "ax2.set_xlabel('Number of trajectories N')\n",
    "ax2.set_ylabel('% Accuracy')\n",
    "ax2.legend()\n",
    "ax2.set_ylim(0, 1)\n",
    "\n",
    "fig2, ax3 = plt.subplots()\n",
    "ax3.plot(Ns, train_acc, 'bo-', label='Training Accuracy')\n",
    "ax3.plot(Ns, np.array(testing_acc), 'bo--', label='Testing Accuracy')\n",
    "ax3.set_title('Classification Accuracy')\n",
    "ax3.set_xlabel('Number of trajectories N')\n",
    "ax3.set_ylabel('% Accuracy')\n",
    "ax3.legend()\n",
    "ax3.set_ylim(0, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
