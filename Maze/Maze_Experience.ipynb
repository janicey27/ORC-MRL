{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Maze Experiment Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will be running the MDP_Model on the Maze problem. This 2D simulation builds on a `gym-maze` package that can be found here: https://github.com/MattChanTK/gym-maze. Before beginning this simulation, please be sure to install the relevant packages on the github **Installation** section (pygame and numpy are also required)!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Demonstration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, a quick demonstration about what the game is. Essentially, there is a robot (circle) that starts on the blue start-point, then keeps taking steps (either with a designated policy or randomly), until it reaches the end point. Here is a simulation to demonstrate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "import gym\n",
    "import gym_maze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the gym environment for a maze\n",
    "env = gym.make(\"maze-sample-5x5-v0\")\n",
    "\n",
    "# Running the maze\n",
    "observation = env.reset()\n",
    "for _ in range(1000):\n",
    "    \n",
    "    env.render()\n",
    "    action = env.action_space.sample() # your agent here (this takes random actions)\n",
    "    observation, reward, done, info = env.step(action)\n",
    "      \n",
    "    if done:\n",
    "      observation = env.reset()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithm Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal on our end is to derive our dataset from the path that the robot takes. Every time it reaches a new coordinate, depending on whether the coordinate is the goal, the robot gets a \"reward.\" With these datapoints, our algorithm should be able to learn an MDP to map out the optimal path through the maze!\n",
    "\n",
    "The basic idea of the algorithm is that we start out with a small number of initial clusters, based solely on the `RISK` value available for each datapoint. Then, we attempt to find contradictions in the cluster transitions, with a contradiction defined as when points in the same cluster and take the same action actually go to different next clusters. During each iteration of the training, the model will split the cluster with the largest contradictions into two smaller clusters, and continue iterating until there are no more contradictions left or until the maximum number of iterations is reached. The result should be an MDP that represents the environment, with all its states and transitions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading relevant packages and functions - make sure to change the `sys.path.append` line with the relevant directory that contains the MDP Algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Working Directory\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "sys.path.append('/Users/janiceyang/Dropbox (MIT)/ORC UROP/Opioids/Algorithm/')\n",
    "#sys.path.append('/Users/Amine/Dropbox (MIT)/Research/Opioids/Opioids Git/Algorithm/')\n",
    "\n",
    "#from MDPtools import *\n",
    "from model import MDP_model\n",
    "from maze_functions import createSamples, opt_model_trajectory, opt_maze_trajectory, plot_paths\n",
    "from testing import cluster_size, next_clusters, training_value_error, purity, plot_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now selecting parameters: here, we decide how many times we want the robot to run through the maze (`N`), when we want to start a new run if the robot takes too long (`T_max`), and the maze that we want the robot to run through (`mazes[x]`, with x being a number from the dictionary).\n",
    "\n",
    "`reseed`' is set to `True` if we want the robot to travel to a different location within each cell every time it moves, while `False` ensures that the robot will start at a certain place in the initial coordinate, but move to the exact same place in the next coordinate. \n",
    "\n",
    "`r` is a float between 0 and 1 indicating the randomness percentage. For instance, if `r = 1`, the robot will take steps in completely random directions 100% of the time, while if `r = 0.5`, it will take half of its steps in the optimal direction (gotten by solving the maze MDP), but the other half randomly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 50\n",
    "T_max = 100\n",
    "r = 0.4\n",
    "\n",
    "\n",
    "# list of maze options to choose from:\n",
    "mazes = {1: 'maze-v0',\n",
    "         2: 'maze-sample-3x3-v0',\n",
    "         3: 'maze-random-3x3-v0',\n",
    "         4: 'maze-sample-5x5-v0',\n",
    "         5: 'maze-random-5x5-v0',\n",
    "         6: 'maze-sample-10x10-v0',\n",
    "         7: 'maze-random-10x10-v0',\n",
    "         8: 'maze-sample-100x100-v0',\n",
    "         9: 'maze-random-100x100-v0',\n",
    "         10: 'maze-random-10x10-plus-v0', # has portals \n",
    "         11: 'maze-random-20x20-plus-v0', # has portals \n",
    "         12: 'maze-random-30x30-plus-v0'} # has portals \n",
    "\n",
    "df = createSamples(N, T_max, mazes[2], r, reseed=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting `FEATURE_0` and `FEATURE_1` are the `x` and `y` coordinates respectively, while `ACTION` corresponds to the (`N`, `S`, `W`, `E`) directions. `RISK` is a reward of `1` if the endstate goal is reached, otherwise it is a negative factor of the maze size for all other locations. The robot does not change cells if it hits a wall, but if `reseed = True`, it can still change locations within the same cell. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we can visualize an example path that we are feeding as data into our algorithm. Note that it is not clear at all that there are grids or walls! The algorithm will train on these `N` paths to attempt to find the optimal policy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_paths(df, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can run the algorithm on the generated dataset! First, we can set some parameters, including `max_k` which is the number of clusters we want to end with, and thus determines the number of iterations during the splitting process. Since initial clustering is based solely on `RISK`, and there are only two groups (end state and all others), there will only be two initial clusters. The expected optimal `max_k` should be the maze size. \n",
    "\n",
    "`pfeatures` tells the algorithm how many features we have in the dataset, in this case 2. \n",
    "\n",
    "`classification` represents the type of classifier we want to use when splitting clusters with points that do not take the action where we found the contradiction. Options for this classifier include `'DecisionTreeClassifier'`, `'LogisticRegression'`, `'RandomForestClassifier'`, `'MLPClassifier'`, and `'AdaBoostClassifier'`. \n",
    "\n",
    "`split_classifier_params` passes in the arguments necessary to this split classifier, including items such as random_state or max_depth. `clustering` indicates the method used to form the initial clusters (based on RISK), with options of `'Agglomerative'`, `'KMeans'`, or `'Birch'`. `n_clusters` can be passed in to set the number of clusters to initialize. If `'Agglomerative'` is used, a `distance_threshold` must also be passed in to determine the distance between clusters (read `sklearn.cluster` documentation on `AgglomerativeClustering` for more details). \n",
    "\n",
    "`precision_thresh` determines the minimum decrease in value error necessary for the model to determine that a different split gives a better clustering. This value attempts to limit model complexity when improvements become only incremental.\n",
    "\n",
    "`eta` is a constant factor that determines the incoherence threshold. Incoherence is defined as the the number of points in each cluster-action pair that do not go to the majority next cluster when a certain action is taken. During training, any clustering that results in a maximum incoherence above `eta*sqrt(n)/c`, where `n` is the number of datapoints given and `c` is the number of clusters at this current split, will be disregarded as too incoherent when finding the optimal clustering.\n",
    "\n",
    "`th` is the threshold value that determines the minimum number of contradictory points required for a split of clusters.\n",
    "\n",
    "`gamma` is the discount factor used when calculating value error, while `h` is the number of timesteps (horizon) on which to optimize the value error. When `h = -1`, we optimize over an infinite horizon.\n",
    "\n",
    "`cv` is the number of folds for cross validation, only relevant when you run `model.fit_CV()`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_k = 9\n",
    "pfeatures = 2\n",
    "\n",
    "classification = 'DecisionTreeClassifier' \n",
    "split_classifier_params = {'random_state':0}\n",
    "clustering = 'Agglomerative'\n",
    "n_clusters = None\n",
    "distance_threshold = 0.5\n",
    "random_state = 0\n",
    "\n",
    "precision_thresh = 1e-14\n",
    "eta = 25\n",
    "th = 0\n",
    "\n",
    "gamma = 1\n",
    "h = -1\n",
    "cv = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can fit an algorithm model to this, using either `m.fit` or `m.fit_CV` (this one runs with `cv` rounds of cross validation, and takes the optimal split). `m.fit` with `optimize=True` will train the model on all the data, and retain the model with an optimal amount of splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = MDP_model()\n",
    "m.fit(df, # df: dataframe in the format ['ID', 'TIME', ...features..., 'RISK', 'ACTION']\n",
    "    pfeatures, # int: number of features\n",
    "    h, # int: time horizon (# of actions we want to optimize)\n",
    "    gamma, # discount factor\n",
    "    max_k, # int: number of iterations\n",
    "    distance_threshold, # clustering diameter for Agglomerative clustering\n",
    "    cv, # number for cross validation\n",
    "    th, # splitting threshold\n",
    "    eta, # incoherence threshold\n",
    "    precision_thresh, # precision threshold\n",
    "    classification, # classification method\n",
    "    split_classifier_params, # classification parameters\n",
    "    clustering,# clustering method from Agglomerative, KMeans, and Birch\n",
    "    n_clusters, # number of clusters for KMeans\n",
    "    random_state,\n",
    "    plot=True,\n",
    "    optimize=False,\n",
    "    verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If `plot = True` above, you should see that the final Value error drops to close to 0 when the number of clusters is 9, which is what should be the case for a 3 by 3 maze! Here is another visualization of how the correct clusters should be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_features(m.df_trained, 'FEATURE_0', 'FEATURE_1', c='OG_CLUSTER')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here is a visualization of how the algorithm currently views where the clusters are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_features(m.df_trained, 'FEATURE_0', 'FEATURE_1', c='CLUSTER')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the clustering may not be completely perfect, and to quantify this, we can look at both the `training_error` and `purity`. The dataframe created by `training_error` tells us how the error was when we had that many clusters, so the error corresponding to `Clusters = 9` should be the lowest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.training_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `purity` compares how much of the new clustering was made up of points from the same original cluster. We can see the percentage breakdown here - the higher the percentage, the better! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "purity(m.df_trained)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see how well our model learned the maze by comparing the optimal path it found to the real solution. The real solution is found by getting the actual transition and reward matrices of the maze, then solving this MDP to get the optimal policy. This is what the correct path should be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_maze_trajectory(mazes[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here, this is what our trained model found the solution to be (remember, our algorithm only got the messy data paths, and did not even know that there were 9 grid spaces!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_model_trajectory(m, mazes[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time for Bigger Mazes!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can generate bigger mazes using the same method as above! Then, we will test to see if the optimal policy found by the maze is the same as the real optimal policy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "import sys\n",
    "sys.path.append('/Users/janiceyang/Dropbox (MIT)/ORC UROP/Opioids/Algorithm/')\n",
    "\n",
    "from model import MDP_model\n",
    "from maze_functions import createSamples, opt_maze_trajectory, opt_model_trajectory, policy_accuracy, \\\n",
    "    get_maze_transition_reward, plot_paths\n",
    "from testing import cluster_size, next_clusters, training_value_error, purity, plot_features, testing_value_error\n",
    "\n",
    "mazes = {1: 'maze-v0',\n",
    "         2: 'maze-sample-3x3-v0',\n",
    "         3: 'maze-random-3x3-v0',\n",
    "         4: 'maze-sample-5x5-v0',\n",
    "         5: 'maze-random-5x5-v0',\n",
    "         6: 'maze-sample-10x10-v0',\n",
    "         7: 'maze-random-10x10-v0',\n",
    "         8: 'maze-sample-100x100-v0',\n",
    "         9: 'maze-random-100x100-v0',\n",
    "         10: 'maze-random-10x10-plus-v0', # has portals \n",
    "         11: 'maze-random-20x20-plus-v0', # has portals \n",
    "         12: 'maze-random-30x30-plus-v0'} # has portals "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting Parameters\n",
    "N = 100\n",
    "T_max = 25\n",
    "r = 0.5\n",
    "maze = mazes[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = createSamples(N, T_max, maze, r, reseed=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's how the transition data looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_paths(df,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking how many points actually reach the end: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['ACTION']=='None']['ID'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting to Algorithm (CV Example)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an example of training with cross validation! For faster training, simply change `m.fit_CV` to `m.fit`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting parameters for model fitting\n",
    "max_k = 20\n",
    "classification = 'DecisionTreeClassifier'\n",
    "split_classifier_params = {'random_state':0, 'max_depth':2}\n",
    "clustering = 'Agglomerative'\n",
    "n_clusters = None\n",
    "distance_threshold = 0.5\n",
    "random_state = 0\n",
    "pfeatures = 2\n",
    "h = -1\n",
    "cv = 5\n",
    "th = 0\n",
    "eta = 25\n",
    "precision_thresh = 1e-14\n",
    "\n",
    "m = MDP_model()\n",
    "m.fit_CV(df, # df: dataframe in the format ['ID', 'TIME', ...features..., 'RISK', 'ACTION']\n",
    "    pfeatures, # int: number of features\n",
    "    h, # int: time horizon (# of actions we want to optimize)\n",
    "    gamma, # discount factor\n",
    "    max_k, # int: number of iterations\n",
    "    distance_threshold, # clustering diameter for Agglomerative clustering\n",
    "    cv, # number for cross validation\n",
    "    th, # splitting threshold\n",
    "    eta, # incoherence threshold, calculated by eta*sqrt(datapoints)/clusters\n",
    "    precision_thresh, # precision threshold\n",
    "    classification, # classification method\n",
    "    split_classifier_params, # classifier params\n",
    "    clustering,# clustering method from Agglomerative, KMeans, and Birch\n",
    "    n_clusters, # number of clusters for KMeans\n",
    "    random_state,\n",
    "    plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observing Policies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's see what the clustering that the model found actually looks like!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_features(m.df_trained, 'FEATURE_0', 'FEATURE_1', 'CLUSTER')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And compare it with a clustering with the actual cells of the Maze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_features(m.df_trained, 'FEATURE_0', 'FEATURE_1', 'OG_CLUSTER')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's see what the optimal policy our model learns is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_model_trajectory(m, maze, 5, 0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And here is an actual simulation of a point through the maze by taking the found optimal policy. Note that we have set a sink node as the bottom left corner, which is where the path will go once it has reached the goal state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, r = get_maze_transition_reward(maze)\n",
    "x0= np.random.rand(2)\n",
    "m.opt_model_trajectory(x0, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Going through each point in the training data set, here is how many (by percentage) our optimal policy actually returned the correct action for. This is essentially the training accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_accuracy(m, maze, m.df_trained)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will generate a new unseen test set using optimal parameters, and see how well the model does. This is the testing error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = createSamples(50, T_max, maze, 0.3, reseed=True)\n",
    "testing_value_error(df_test, m.df_trained, m.m, m.pfeatures, relative=False, h=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a metric that measures how good our classification model is in putting points in the right cluster:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.clus_pred_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, here is the optimal policy for reference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_maze_trajectory(maze)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performance Based On Data Size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've seen how one model can perform based on one generated dataset, let's see how the model performs when given different numbers of paths to learn from. We will use a dataset with 200 paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 200\n",
    "T_max = 25\n",
    "r = 0.5\n",
    "maze = mazes[4]\n",
    "\n",
    "df = createSamples(N, T_max, maze, r, reseed=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to see how well the model trains on different subsets of the data, starting with when it only has access to the first 10 paths, `N=10`, all the way to all 200 paths, `N=200`. The subsets we look at can be seen in the list `Ns`. \n",
    "\n",
    "We will train a separate model for each data-size, then plot some trends in how the algorithm learns as training data increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting parameters for model fitting\n",
    "max_k = 25\n",
    "classification = 'DecisionTreeClassifier'\n",
    "split_classifier_params = {'random_state':0, 'max_depth':2}\n",
    "clustering = 'Agglomerative'\n",
    "n_clusters = None\n",
    "distance_threshold = 0.5\n",
    "random_state = 0\n",
    "pfeatures = 2\n",
    "gamma = 1\n",
    "actions = [0, 1, 2, 3]\n",
    "h = -1\n",
    "cv = 5\n",
    "th = 0\n",
    "eta = 25\n",
    "precision_thresh = 1e-14\n",
    "\n",
    "Ns = [10, 20, 30, 40, 50, 70, 90, 110, 130, 150, 170, 200]\n",
    "df_full = df.copy()\n",
    "\n",
    "models=[]\n",
    "    \n",
    "# Training models \n",
    "for n in Ns:\n",
    "    df_small = df_full.loc[df_full['ID']<n]\n",
    "    \n",
    "    m = MDP_model()\n",
    "    m.fit(df_small, # df: dataframe in the format ['ID', 'TIME', ...features..., 'RISK', 'ACTION']\n",
    "        pfeatures, # int: number of features\n",
    "        h, # int: time horizon (# of actions we want to optimize)\n",
    "        gamma, # discount factor\n",
    "        max_k, # int: number of iterations\n",
    "        distance_threshold, # clustering diameter for Agglomerative clustering\n",
    "        cv, # number for cross validation\n",
    "        th, # splitting threshold\n",
    "        eta, # incoherence threshold\n",
    "        precision_thresh, # precision threshold\n",
    "        classification, # classification method\n",
    "        split_classifier_params, # classification params\n",
    "        clustering,# clustering method from Agglomerative, KMeans, and Birch\n",
    "        n_clusters, # number of clusters for KMeans\n",
    "        random_state,\n",
    "        plot=False,\n",
    "        optimize=True)\n",
    "    print('N=', n, ' completed')\n",
    "    models.append(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are going to evaluate how the various models have performed in terms of their in-sample training error (at the point where the model has reached the optimal clustering and stopped training), as well as the out-of-sample testing error based on a newly generated dataset with the same parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from testing import testing_value_error\n",
    "\n",
    "N = 200\n",
    "T_max = 25\n",
    "r = 0.4\n",
    "maze = mazes[4]\n",
    "# Creating a test set with same parameters as training set\n",
    "df_test = createSamples(N, T_max, maze, r, reseed=True)\n",
    "\n",
    "# In & out sample training and testing value errors: \n",
    "training_errors = []\n",
    "testing_errors = []\n",
    "for m in models: \n",
    "    tr_err = m.training_error.loc[m.training_error['Clusters']==m.opt_k]['Error'].min()\n",
    "    te_err = testing_value_error(df_test, m.df_trained, m.m, m.pfeatures, gamma, relative=False, h=-1)\n",
    "    training_errors.append(tr_err)\n",
    "    testing_errors.append(te_err)\n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.plot(Ns, training_errors, label='Training Error')\n",
    "ax1.plot(Ns, testing_errors, label='Testing Error')\n",
    "ax1.set_title('Testing and Training Errors by N')\n",
    "ax1.set_xlabel('N training data size')\n",
    "ax1.set_ylabel('Error')\n",
    "ax1.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also want to measure both training and testing accuracies, measured as how well the model learns and maps each point to the correct original clustering of the maze, and how these values change as data size increases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from testing import generalization_accuracy\n",
    "\n",
    "tr_acc, test_acc = generalization_accuracy(models, df_test, Ns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimality Gap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we want to measure the optimality gap, where given a point that begins randomly in the starting cell, we want to measure the value difference after `t_max` steps between two scenarios: 1) if this point takes only the optimal action through the maze, and 2) if this point takes the action that the model prescribes based on the model's solved MDP. In both scenarios, the point progresses through the maze according to the actual maze dynamics; the only difference lies in what sequence of actions it is given.\n",
    "\n",
    "\n",
    "We will once again plot the change in this value as data size increases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from maze_functions import get_maze_MDP, get_maze_transition_reward, value_diff\n",
    "\n",
    "# Set Parameters\n",
    "P, R = get_maze_MDP(maze)\n",
    "K = 100\n",
    "f, rw = get_maze_transition_reward(maze)\n",
    "\n",
    "opt_gap = value_diff(models, Ns, K, T_max, P, R, f, rw)\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.plot(Ns, opt_gap)\n",
    "ax1.set_title('Optimality Gap by Data Size N')\n",
    "ax1.set_xlabel('N training data size')\n",
    "ax1.set_ylabel('|V_alg-V*|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
